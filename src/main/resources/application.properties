
quarkus.log.console.format=%d{HH:mm:ss} %-5p [%c{2.}] (%t) %s%e%n
quarkus.log.console.level=FINE
quarkus.log.console.enable=true
quarkus.ssl.native=false
temperature.threshold=90.0
temperature.max.occurence.count=5

anomalydetection.scoring/mp-rest/url=${ANOMALY_DETECTION_URL}
anomalydetection.scoring/mp-rest/scope=javax.inject.Singleton
anomalydetection.scoring.wmlToken=${WML_TOKEN}

# # Configure the Kafka sink (we write to it)
# mp.messaging.outgoing.reefer.connector=smallrye-kafka
# mp.messaging.outgoing.reefer.topic=${REEFER_TOPIC:reefers}
# mp.messaging.outgoing.reefer.key.serializer=org.apache.kafka.common.serialization.StringSerializer
# mp.messaging.outgoing.reefer.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer

# outgoing
# to generate container data
mp.messaging.outgoing.reefer-telemetry-out.connector=smallrye-kafka
mp.messaging.outgoing.reefer-telemetry-out.topic=refarcTopic
mp.messaging.outgoing.reefer-telemetry-out.group.id=cold-chain-agent-out
mp.messaging.outgoing.reefer-telemetry-out.key.serializer=org.apache.kafka.common.serialization.StringSerializer
mp.messaging.outgoing.reefer-telemetry-out.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer

# Configure the Kafka source (we read from it)
# to read data from topic `refarcTopic`
mp.messaging.incoming.reefer-telemetry.connector=smallrye-kafka
mp.messaging.incoming.reefer-telemetry.topic=refarcTopic
mp.messaging.incoming.reefer-telemetry.group.id=cold-chain-agent-in
mp.messaging.incoming.reefer-telemetry.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.reefer-telemetry.value.deserializer=ibm.gse.eda.vaccine.coldchainagent.infrastructure.TelemetryDeserializer
#  mp.messaging.incoming.reefer-telemetry.ssl.truststore.location=${CERT_LOCATION}

#### Config shared between all kafka connections
# bootstrap server is the only config needed for plain insercure local kafka instance
mp.messaging.connector.smallrye-kafka.bootstrap.servers=${KAFKA_BOOTSTRAP_SERVERS}
# If connecting to Event Streams on IBM Cloud or to any Kafka deployment with SSL security
# mp.messaging.connector.smallrye-kafka.security.protocol=SASL_SSL
# mp.messaging.connector.smallrye-kafka.sasl.mechanism=SCRAM-SHA-512
# # Make sure you set the username and API key at the end
# mp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username=${SCRAM_USER} password=${SCRAM_PWD};
# # TLS properties
# mp.messaging.connector.smallrye-kafka.ssl.truststore.location=${CERT_LOCATION}
# # # Password for the truststore
# mp.messaging.connector.smallrye-kafka.ssl.truststore.password=${CERT_PWD}
# mp.messaging.connector.smallrye-kafka.ssl.protocol=TLSv1.2

# for topology or @produces on TelemetryAssessor.java file
quarkus.kafka-streams.application-server=${hostname}:8080
hostname=localhost
quarkus.kafka-streams.bootstrap-servers=${KAFKA_BOOTSTRAP_SERVERS}
quarkus.kafka-streams.topics=refarcTopic
quarkus.kafka-streams.application-id=stream-reader

# # streams options
# kafka-streams.cache.max.bytes.buffering=10240
# kafka-streams.commit.interval.ms=1000
# kafka-streams.metadata.max.age.ms=500
# kafka-streams.metrics.recording.level=DEBUG
# # Use sub-folder of embedded broker, so it gets cleaned by KafkaResource between re-runs
# # This does not work for native tests, manually clean-up /tmp/kafka-streams/temperature-aggregator
# %test.kafka-streams.state.dir=target/data/kafka-data/stores

# quarkus.log.console.enable=true
# quarkus.log.console.level=INFO