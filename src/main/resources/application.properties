quarkus.log.console.format=%d{HH:mm:ss} %-5p [%c{2.}] (%t) %s%e%n
quarkus.log.console.level=INFO
quarkus.log.console.enable=true
quarkus.log.category."ibm.gse.eda".level=${EDA_LOGGING_LEVEL:DEBUG}
quarkus.log.category."ibm.gse.eda".min-level=DEBUG
quarkus.ssl.native=false
quarkus.package.type=fast-jar
quarkus.swagger-ui.always-include=true
quarkus.http.cors=true
quarkus.http.port=8080


#################################
# Source to Image to openshift 
quarkus.openshift.expose=true
quarkus.container-image.group=ibmcase
quarkus.container-image.registry=image-registry.openshift-image-registry.svc:5000
quarkus.openshift.labels.app=reefer-monitoring-agent
quarkus.container-image.name=reefer-monitoring-agent

# Define properties for yaml files generation
quarkus.openshift.env.configmaps=reefer-monitoring-agent-cm
quarkus.openshift.env.secrets=reefer-monitoring-agent-secret
quarkus.openshift.env.fields.POD_IP=status.podIP
# Cluster certificate
%prod.quarkus.openshift.env.mapping.KAFKA_SSL_TRUSTSTORE_PASSWORD.from-secret=${KAFKA_CA_CERT_NAME:kafka-cluster-ca-cert}
%prod.quarkus.openshift.env.mapping.KAFKA_SSL_TRUSTSTORE_PASSWORD.with-key=ca.password
%prod.quarkus.openshift.mounts.kafka-cert.path=/deployments/certs/server
%prod.quarkus.openshift.secret-volumes.kafka-cert.secret-name=${KAFKA_CA_CERT_NAME:kafka-cluster-ca-cert}
# TLS user
%prod.quarkus.openshift.env.mapping.KAFKA_SSL_KEYSTORE_PASSWORD.from-secret=${KAFKA_USER:tls-user}
%prod.quarkus.openshift.env.mapping.KAFKA_SSL_KEYSTORE_PASSWORD.with-key=user.password
%prod.quarkus.openshift.mounts.user-cert.path=/deployments/certs/user
%prod.quarkus.openshift.secret-volumes.user-cert.secret-name=${KAFKA_USER:tls-user}

#################################
# Kafka producer - as we use schema we need scram to connect to the schema registry
# so in this case to simplify the configuration we can use scram to connect to brokers
# Mutual TLS on OCP
%prod.kafka.security.protocol=SSL
%prod.kafka.ssl.protocol=TLSv1.2
%prod.kafka.ssl.trustore.location=/deployments/certs/server/ca.p12
%prod.kafka.ssl.trustore.type=PKCS12
%prod.kafka.ssl.keystore.location=/deployments/certs/user/user.p12
%prod.kafka.ssl.keystore.type=PKCS12
# NOT sure the lines below are needed as the lines above should work
%prod.quarkus.kafka-streams.security.protocol=SSL
%prod.quarkus.kafka-streams.ssl.keystore.location=/deployments/certs/user/user.p12
%prod.quarkus.kafka-streams.ssl.keystore.password=${KAFKA_SSL_KEYSTORE_PASSWORD}
%prod.quarkus.kafka-streams.ssl.keystore.type=PKCS12
%prod.quarkus.kafka-streams.ssl.protocol=TLSv1.2
%prod.quarkus.kafka-streams.ssl.truststore.location=/deployments/certs/server/ca.p12
%prod.quarkus.kafka-streams.ssl.truststore.password=${KAFKA_SSL_TRUSTSTORE_PASSWORD}
%prod.quarkus.kafka-streams.ssl.truststore.type=PKCS12

##########################
# SCRAM Properties       #
##########################
%staging.quarkus.kafka-streams.security.protocol=SASL_SSL
%staging.quarkus.kafka-streams.sasl.mechanism=SCRAM-SHA-512
%staging.quarkus.kafka-streams.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username=${KAFKA_USER} password=${KAFKA_PASSWORD};

#######################
# Application specifics
#######################
temperature.threshold=-15.0
temperature.max.occurence.count=10
prediction.enabled=false
cp4d.auth.url=${CP4D_AUTH_URL:"https://zen-cpd-zen.apps.cpdv35-swat.cpd-daell.com/icp4d-api/v1/authorize"}
cp4d.user=${CP4D_USER:""}
cp4d.api.key=${CP4D_API_KEY:""}
%prod.anomalydetection.scoring.url=${ANOMALY_DETECTION_URL:""}
%prod.anomalydetection.scoring/mp-rest/url=${ANOMALY_DETECTION_URL:""}
%prod.anomalydetection.scoring/mp-rest/scope=javax.inject.Singleton

#### Config shared between all kafka connections

##########################

# when cold chain violation or anomaly is detected send message to reefer Topic

mp.messaging.outgoing.reeferAlerts.connector=smallrye-kafka
mp.messaging.outgoing.reeferAlerts.topic=${ALERT_TOPIC:vaccine.reeferAlerts}
mp.messaging.outgoing.reeferAlerts.key.serializer=org.apache.kafka.common.serialization.StringSerializer
mp.messaging.outgoing.reeferAlerts.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer


# Telemetries to process for reactive messaging
mp.messaging.incoming.telemetries.connector=smallrye-kafka
mp.messaging.incoming.telemetries.topic=${TELEMETRY_TOPIC:telemetries}
mp.messaging.incoming.telemetries.group.id=reefer-monitoring-agent
mp.messaging.incoming.telemetries.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
mp.messaging.incoming.telemetries.value.deserializer=ibm.gse.eda.vaccine.coldchainagent.infrastructure.TelemetryDeserializer


# hostname=localhost
quarkus.reactive-messaging.health.enabled=false
quarkus.kafka-streams.application-server=${POD_IP}:8080
quarkus.kafka-streams.topics=${TELEMETRY_TOPIC:telemetries}
quarkus.kafka-streams.application-id=cold-chain-agent
# Connection settings
quarkus.kafka-streams.bootstrap-servers=${KAFKA_BOOTSTRAP_SERVERS}
quarkus.kafka-streams.default.deserialization.exception.handler=org.apache.kafka.streams.errors.LogAndContinueExceptionHandler

